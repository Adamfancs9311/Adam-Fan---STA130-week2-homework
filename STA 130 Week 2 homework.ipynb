{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac097d33",
   "metadata": {},
   "source": [
    "1. Begin (or restart) part \"3(a)\" of the TUT Demo and interact with a ChatBot to make sure you understand how each part the Monte Hall problem code above works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29031c6",
   "metadata": {},
   "source": [
    "prompt:\n",
    "\n",
    "Can you explain the following code part by part of how each section works: #code from TUT demo 3. a) \n",
    "This code simulates the Monty Hall problem and uses a \"swap\" strategy to calculate the probability of winning by switching doors after a losing door is revealed. Here's a step-by-step breakdown of how each section works:\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "### 1. Imports and Variables Setup\n",
    "```python\n",
    "import numpy as np\n",
    "all_door_options = (1, 2, 3)  # tuple of the three doors (1, 2, 3)\n",
    "my_door_choice = 1  # initially choose door 1 (can be any)\n",
    "i_won = 0  # counter to track number of wins\n",
    "reps = 100000  # number of repetitions for simulation\n",
    "```\n",
    "- `numpy` is imported to use its random number generation functions.\n",
    "- `all_door_options` is a tuple containing the three possible door numbers.\n",
    "- `my_door_choice` initializes your first door choice as door 1.\n",
    "- `i_won` tracks how many times the player wins (i.e., picks the winning door after the switch).\n",
    "- `reps` defines the number of iterations (simulations) to run (100,000).\n",
    "\n",
    "### 2. Main Loop: Simulating the Game\n",
    "```python\n",
    "for i in range(reps):\n",
    "```\n",
    "- The loop iterates `reps` times to simulate the Monty Hall game multiple times.\n",
    "\n",
    "### 3. Randomly Select the Winning Door\n",
    "```python\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "```\n",
    "- `np.random.choice` randomly picks one of the three doors to be the winning door in each simulation.\n",
    "\n",
    "### 4. List of Doors and Removing the Winning Door\n",
    "```python\n",
    "    all_door_options_list = list(all_door_options)  # convert tuple to a list for mutability\n",
    "    all_door_options_list.remove(secret_winning_door)  # remove the winning door from the list\n",
    "```\n",
    "- The tuple `all_door_options` is converted into a list so that doors can be removed as part of the simulation.\n",
    "- The winning door is removed from the list so that it can't be revealed as a \"goat\" door.\n",
    "\n",
    "### 5. Try to Remove Player's Initial Door Choice\n",
    "```python\n",
    "    try:\n",
    "        all_door_options_list.remove(my_door_choice)\n",
    "    except:\n",
    "        pass\n",
    "```\n",
    "- The code attempts to remove the player's initial door choice (`my_door_choice`) from the list. If this door was already removed (because it was the winning door), the `except` block is used to skip over the error and continue.\n",
    "\n",
    "### 6. Reveal a Goat Door\n",
    "```python\n",
    "    goat_door_reveal = np.random.choice(all_door_options_list)\n",
    "    all_door_options_list.remove(goat_door_reveal)\n",
    "```\n",
    "- A \"goat\" door is revealed by randomly selecting from the remaining doors (i.e., the doors that are not the winning door or the player's initial choice).\n",
    "- Once the \"goat\" door is revealed, it is removed from the list, leaving only one door for the player to switch to.\n",
    "\n",
    "### 7. Add Back the Winning Door (If Needed)\n",
    "```python\n",
    "    if secret_winning_door != my_door_choice:\n",
    "        all_door_options_list.append(secret_winning_door)\n",
    "```\n",
    "- If the player's initial door choice is not the winning door, the winning door is added back to the list. This is necessary because only one door remains for the player to switch to.\n",
    "\n",
    "### 8. Switch the Door\n",
    "```python\n",
    "    my_door_choice = all_door_options_list[0]\n",
    "```\n",
    "- The player switches to the only remaining door (which is either the winning door or another \"goat\" door).\n",
    "\n",
    "### 9. Check if Player Won and Update the Win Counter\n",
    "```python\n",
    "    if my_door_choice == secret_winning_door:\n",
    "        i_won += 1\n",
    "```\n",
    "- After switching doors, the code checks if the new door choice is the winning door. If so, the win counter (`i_won`) is incremented.\n",
    "\n",
    "### 10. Output the Probability of Winning\n",
    "```python\n",
    "i_won / reps\n",
    "```\n",
    "- The final output is the proportion of times the player won by switching, which gives the empirical probability of winning using the switch strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b670ece",
   "metadata": {},
   "source": [
    "2. Extend your ChatBot sessions to now address part \"3(b)\" of the TUT Demo and interact with your ChatBot to see if it can suggest a simpler, more streamlined way to code up this for loop simulation so the process is more clear and easier to understand; then, describe any preferences you have in terms of readibility or explainability between the original code and the code improvements suggested by the ChatBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048bf72",
   "metadata": {},
   "source": [
    "Prompt:\n",
    "\n",
    "based on this question suggest an improved streamlined version of the for loop simulation code that might be easier to explain and understand\n",
    "\n",
    "\n",
    "ChatGPT:\n",
    "\n",
    "Here’s a more streamlined and readable version of the Monte Hall simulation. The key idea is to simplify the logic, reduce the number of steps inside the loop, and make the code more intuitive while keeping the same functionality.\n",
    "\n",
    "### Improved Simulation Code:\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "all_doors = [1, 2, 3]  # possible door options\n",
    "reps = 100000  # number of repetitions\n",
    "wins = 0  # counter for wins when switching\n",
    "\n",
    "for _ in range(reps):\n",
    "    # Randomly assign the winning door and player's initial choice\n",
    "    winning_door = np.random.choice(all_doors)\n",
    "    player_choice = np.random.choice(all_doors)\n",
    "    \n",
    "    # Reveal a goat door (a door that isn't the winning door or the player's choice)\n",
    "    remaining_doors = [door for door in all_doors if door != player_choice and door != winning_door]\n",
    "    revealed_goat = np.random.choice(remaining_doors)\n",
    "    \n",
    "    # Switch the player's choice to the remaining unopened door\n",
    "    switched_choice = [door for door in all_doors if door != player_choice and door != revealed_goat][0]\n",
    "    \n",
    "    # Check if the player wins after switching\n",
    "    if switched_choice == winning_door:\n",
    "        wins += 1\n",
    "\n",
    "# Calculate the probability of winning by switching\n",
    "win_probability = wins / reps\n",
    "print(f\"Winning probability by switching: {win_probability:.4f}\")\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **`all_doors = [1, 2, 3]`**: This stores the three possible door choices (1, 2, and 3) in a list. Lists are easier to manipulate (compared to tuples).\n",
    "\n",
    "2. **`reps = 100000`**: This is the number of repetitions (100,000 games) to simulate.\n",
    "\n",
    "3. **`wins = 0`**: A counter to track how many times the player wins by switching doors.\n",
    "\n",
    "4. **Main loop (`for _ in range(reps)`)**: Runs the simulation `reps` times.\n",
    "    - **`winning_door = np.random.choice(all_doors)`**: Randomly selects a winning door for each iteration.\n",
    "    - **`player_choice = np.random.choice(all_doors)`**: Randomly selects the player’s initial door choice.\n",
    "    \n",
    "5. **Revealing the Goat Door**:\n",
    "    - **`remaining_doors = [door for door in all_doors if door != player_choice and door != winning_door]`**: This generates a list of doors that are not the player’s initial choice and not the winning door (i.e., the \"goat\" doors).\n",
    "    - **`revealed_goat = np.random.choice(remaining_doors)`**: Randomly selects one of the remaining \"goat\" doors to reveal.\n",
    "\n",
    "6. **Switching Doors**:\n",
    "    - **`switched_choice = [door for door in all_doors if door != player_choice and door != revealed_goat][0]`**: The player switches to the only door that isn’t their initial choice or the revealed goat door.\n",
    "\n",
    "7. **Check if the switched choice is the winning door**:\n",
    "    - **`if switched_choice == winning_door:`**: If the new door choice (after switching) is the winning door, the player wins, and `wins` is incremented.\n",
    "\n",
    "8. **Final Probability Calculation**:\n",
    "    - **`win_probability = wins / reps`**: After all simulations, the probability of winning by switching is calculated by dividing the number of wins by the total number of games (`reps`).\n",
    "    - **`print(f\"Winning probability by switching: {win_probability:.4f}\")`**: Outputs the result.\n",
    "\n",
    "### Key Improvements:\n",
    "- **Simplified Logic**: By directly generating the remaining doors and revealing the goat, we eliminate the need for multiple `remove()` calls.\n",
    "- **More Pythonic**: List comprehensions make the code more compact and readable.\n",
    "- **Reduced Complexity**: Fewer steps, clearer logic flow, and more intuitive switching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8363b7",
   "metadata": {},
   "source": [
    "3. Submit your preferred version of the Monty Hall problem that is verified to be running and working with a final printed output of the code; then, add code comments explaining the purpose of each line of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed85896",
   "metadata": {},
   "source": [
    "I would personally prefer ChatGPT's version of code considering it's not using other complicated function in python but still simplified the logic and readibility in the for loop. Additionally, ChatGPT also involve the player choice door into the for loop which will also be random so the simulation is more accurate. However I would change some comment provided by ChatGPT. The comments with double ## are the comments I made. \n",
    "\n",
    "### Improved Simulation Code:\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "all_doors = [1, 2, 3]  # possible door options\n",
    "reps = 100000  # number of repetitions\n",
    "wins = 0  # counter for wins when switching\n",
    "\n",
    "for _ in range(reps):\n",
    "    # Randomly assign the winning door and player's initial choice\n",
    "    ## They can be the same one!!\n",
    "    winning_door = np.random.choice(all_doors)\n",
    "    player_choice = np.random.choice(all_doors)\n",
    "    \n",
    "    # Reveal a goat door (a door that isn't the winning door or the player's choice)\n",
    "    ## Iterate through all the doors in all_doors\n",
    "    remaining_doors = [door for door in all_doors if door != player_choice and door != winning_door]\n",
    "    \n",
    "    ## Pick one door from remaining_doors *** usually only one door in the list since according to calculation, winning_door and palyer_choice door will not be the same one\n",
    "    revealed_goat = np.random.choice(remaining_doors)\n",
    "    \n",
    "    # Switch the player's choice to the remaining unopened door\n",
    "    ## Switch choice by removing all_doors the door that's confirm as goat and the player_choice door\n",
    "    switched_choice = [door for door in all_doors if door != player_choice and door != revealed_goat][0]\n",
    "    \n",
    "    # Check if the player wins after switching\n",
    "    if switched_choice == winning_door:\n",
    "        wins += 1\n",
    "\n",
    "# Calculate the probability of winning by switching\n",
    "win_probability = wins / reps\n",
    "print(f\"Winning probability by switching: {win_probability:.4f}\")\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "\n",
    "1. **`all_doors = [1, 2, 3]`**: This stores the three possible door choices (1, 2, and 3) in a list. Lists are easier to manipulate (compared to tuples).\n",
    "\n",
    "2. **`reps = 100000`**: This is the number of repetitions (100,000 games) to simulate.\n",
    "\n",
    "3. **`wins = 0`**: A counter to track how many times the player wins by switching doors.\n",
    "\n",
    "4. **Main loop (`for _ in range(reps)`)**: Runs the simulation `reps` times.\n",
    "    - **`winning_door = np.random.choice(all_doors)`**: Randomly selects a winning door for each iteration.\n",
    "    - **`player_choice = np.random.choice(all_doors)`**: Randomly selects the player’s initial door choice.\n",
    "    \n",
    "5. **Revealing the Goat Door**:\n",
    "    - **`remaining_doors = [door for door in all_doors if door != player_choice and door != winning_door]`**: This generates a list of doors that are not the player’s initial choice and not the winning door (i.e., the \"goat\" doors).\n",
    "    - **`revealed_goat = np.random.choice(remaining_doors)`**: Randomly selects one of the remaining \"goat\" doors to reveal.\n",
    "\n",
    "6. **Switching Doors**:\n",
    "    - **`switched_choice = [door for door in all_doors if door != player_choice and door != revealed_goat][0]`**: The player switches to the only door that isn’t their initial choice or the revealed goat door.\n",
    "\n",
    "7. **Check if the switched choice is the winning door**:\n",
    "    - **`if switched_choice == winning_door:`**: If the new door choice (after switching) is the winning door, the player wins, and `wins` is incremented.\n",
    "\n",
    "8. **Final Probability Calculation**:\n",
    "    - **`win_probability = wins / reps`**: After all simulations, the probability of winning by switching is calculated by dividing the number of wins by the total number of games (`reps`).\n",
    "    - **`print(f\"Winning probability by switching: {win_probability:.4f}\")`**: Outputs the result.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5c7d9",
   "metadata": {},
   "source": [
    "Summary so far\n",
    "\n",
    "prompt:\n",
    "\n",
    "summaries all of our conversation so far \n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "So far, you've asked for an explanation and improvement of a Monte Hall simulation code. Here's a summary:\n",
    "\n",
    "1. **Initial Code Explanation**: You provided a Monte Hall simulation written in Python, and I explained it part by part, breaking down how each section works:\n",
    "   - Importing libraries and setting up variables.\n",
    "   - A loop that simulates picking doors, revealing a goat door, and switching doors.\n",
    "   - The win counter updates based on whether switching results in choosing the winning door.\n",
    "   - The final output calculates the win probability by switching doors.\n",
    "\n",
    "2. **Improved Version**: I then provided a more streamlined and intuitive version of the simulation:\n",
    "   - Used list comprehensions and simpler logic to reveal the goat door and switch the player's choice.\n",
    "   - Reduced the number of steps inside the loop, making the code more Pythonic and readable while maintaining the same functionality.\n",
    "\n",
    "Let me know if you'd like to dive deeper into any part!\n",
    "\n",
    "\n",
    "Link: https://chatgpt.com/share/66ecc231-9394-800d-b6f7-5d10cfff54f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f0f1a",
   "metadata": {},
   "source": [
    "*** Wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe101a6",
   "metadata": {},
   "source": [
    "4. Watch the embedded video tutorial on Markov chains in the next Jupyter cell below to understand their application and relevance for ChatBots; then, after watching the video, start a new ChatBot session by prompting that you have code that creates a \"Markovian ChatBot\"; show it the first version of the \"Markovian ChatBot code\" below; and interact with the ChatBot session to make sure you understand how the original first version of the \"Markovian ChatBot code\" works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9579f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"550\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/56mGTszb_iM\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f5ccc1bb350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Markov Chains and Text Generation\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('56mGTszb_iM', width = 550)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb755112",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "prompt:\n",
    "\n",
    "you have code that creates a \"Markovian ChatBot\"\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "Yes, I can help you build a basic Markovian chatbot! A Markov chatbot is based on a **Markov chain**, which models probabilistic transitions between states. In the context of a chatbot, the states are words or phrases, and the transitions represent the likelihood of one word following another based on training data.\n",
    "\n",
    "Here's how you can build one in Python:\n",
    "\n",
    "1. **Train the chatbot**: By feeding it a large text corpus to analyze, it builds a transition table.\n",
    "2. **Generate text**: Based on the transition table, the bot can generate responses by moving from one word to another probabilistically.\n",
    "\n",
    "Here’s a basic implementation of a Markov chatbot:\n",
    "\n",
    "### Step-by-Step Code:\n",
    "\n",
    "```python\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class MarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the Markov chain\n",
    "        self.markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create pairs of consecutive words and populate the Markov chain\n",
    "        for i in range(len(words) - 1):\n",
    "            self.markov_chain[words[i]].append(words[i + 1])\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed word.\n",
    "        \"\"\"\n",
    "        if not seed or seed not in self.markov_chain:\n",
    "            seed = random.choice(list(self.markov_chain.keys()))\n",
    "        \n",
    "        response = [seed]\n",
    "        current_word = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the Markov chain\n",
    "        for _ in range(length - 1):\n",
    "            if current_word in self.markov_chain:\n",
    "                next_word = random.choice(self.markov_chain[current_word])\n",
    "                response.append(next_word)\n",
    "                current_word = next_word\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize bot\n",
    "    bot = MarkovChatBot()\n",
    "    \n",
    "    # Train the bot with some text data\n",
    "    training_data = \"\"\"\n",
    "    Hello, how are you? I am a chatbot that learns from conversations. You can talk to me about anything. \n",
    "    What do you want to talk about today? I'm happy to help you with your questions!\n",
    "    \"\"\"\n",
    "    \n",
    "    bot.train(training_data)\n",
    "    \n",
    "    # Generate a response\n",
    "    seed_word = \"hello\"\n",
    "    response = bot.generate_response(seed=seed_word, length=20)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **Training**: The `train()` method builds a Markov chain by breaking down text into word pairs. Each word (a state) leads to the words that follow it.\n",
    "2. **Generating Responses**: The `generate_response()` method generates a random response based on the probabilities learned from the training data. It starts with a seed word and keeps adding words based on the transition probabilities.\n",
    "3. **Markov Chain**: The `markov_chain` is a dictionary where each key is a word, and its value is a list of words that can follow that word in the text.\n",
    "\n",
    "You can extend this by training the bot on larger datasets to make the responses more coherent. Would you like me to walk through any part of it in more detail?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2de825",
   "metadata": {},
   "source": [
    "second promt:\n",
    "\n",
    "train it using a series of stories with different characters.\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "To train the Markov chatbot using a series of stories with different characters, you need to feed it text that contains those stories. The chatbot will then build a Markov chain based on the patterns it observes in the stories. Here’s a step-by-step guide to training the chatbot with multiple stories:\n",
    "\n",
    "### 1. Prepare Story Data\n",
    "\n",
    "You can use any stories you like, preferably those that are in text form. For demonstration purposes, let's create some sample stories with different characters.\n",
    "\n",
    "```python\n",
    "# Example stories\n",
    "story_data = \"\"\"\n",
    "Once upon a time, in a small village, there lived a farmer named John. Every morning, John would wake up early \n",
    "and tend to his crops. He loved his farm and worked hard to make sure his animals were happy.\n",
    "\n",
    "In another kingdom far away, a young princess named Eliza dreamed of exploring the world. She would sit by her window, \n",
    "gazing at the horizon, longing for an adventure.\n",
    "\n",
    "One day, John and Eliza met by chance in a bustling market. They quickly became friends and shared their dreams of adventure. \n",
    "Together, they embarked on a journey through forests and mountains, facing challenges and making new friends.\n",
    "\"\"\"\n",
    "\n",
    "# Add another story for diversity\n",
    "more_story_data = \"\"\"\n",
    "In a distant land, there lived a warrior named Marcus. He was brave and strong, feared by his enemies. \n",
    "Despite his tough exterior, Marcus had a kind heart. He would protect the weak and fight for justice.\n",
    "\n",
    "One day, while wandering through the desert, Marcus encountered a merchant who had lost his way. Marcus offered to help, \n",
    "and together, they found the nearest oasis. Grateful, the merchant gave Marcus a rare map that led to a hidden treasure.\n",
    "\n",
    "Meanwhile, in the same land, there was a brilliant inventor named Sophia. She was known for creating marvelous machines. \n",
    "Sophia and Marcus eventually crossed paths, and they teamed up to build incredible inventions that would change the world.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 2. Train the Chatbot on Multiple Stories\n",
    "\n",
    "Now, we’ll modify the training function to train the chatbot on multiple stories.\n",
    "\n",
    "```python\n",
    "class MarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the Markov chain\n",
    "        self.markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create pairs of consecutive words and populate the Markov chain\n",
    "        for i in range(len(words) - 1):\n",
    "            self.markov_chain[words[i]].append(words[i + 1])\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed word.\n",
    "        \"\"\"\n",
    "        if not seed or seed not in self.markov_chain:\n",
    "            seed = random.choice(list(self.markov_chain.keys()))\n",
    "        \n",
    "        response = [seed]\n",
    "        current_word = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the Markov chain\n",
    "        for _ in range(length - 1):\n",
    "            if current_word in self.markov_chain:\n",
    "                next_word = random.choice(self.markov_chain[current_word])\n",
    "                response.append(next_word)\n",
    "                current_word = next_word\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the bot\n",
    "    bot = MarkovChatBot()\n",
    "    \n",
    "    # Train the bot on multiple stories\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    # Generate a response based on the seed word\n",
    "    seed_word = \"john\"  # Start with a character's name\n",
    "    response = bot.generate_response(seed=seed_word, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **Multiple Stories**: We have two different stories with multiple characters (`John`, `Eliza`, `Marcus`, `Sophia`). You can add as many stories as you like, and the bot will train on all of them, identifying patterns.\n",
    "2. **Training the Bot**: We call the `train()` method for each story or batch of text to build a more robust Markov chain.\n",
    "3. **Generating Responses**: When generating responses, the bot will mix language patterns learned from different stories. You can give it a seed word (e.g., a character's name) to steer the response in a particular direction.\n",
    "\n",
    "### Example Response:\n",
    "\n",
    "After training the bot with the stories, running the code might produce output like:\n",
    "\n",
    "```text\n",
    "Bot's response: john would wake up early and tend to his crops. he loved the world. one day, john and eliza dreamed of exploring the map that led to a hidden treasure.\n",
    "```\n",
    "\n",
    "You can extend this further by adding more complex stories and different genres to train the bot for more varied outputs. Would you like to try training the bot with specific stories of your own?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0605906d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's response: hello how are you with your questions\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class MarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the Markov chain\n",
    "        self.markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create pairs of consecutive words and populate the Markov chain\n",
    "        for i in range(len(words) - 1):\n",
    "            self.markov_chain[words[i]].append(words[i + 1])\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed word.\n",
    "        \"\"\"\n",
    "        if not seed or seed not in self.markov_chain:\n",
    "            seed = random.choice(list(self.markov_chain.keys()))\n",
    "        \n",
    "        response = [seed]\n",
    "        current_word = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the Markov chain\n",
    "        for _ in range(length - 1):\n",
    "            if current_word in self.markov_chain:\n",
    "                next_word = random.choice(self.markov_chain[current_word])\n",
    "                response.append(next_word)\n",
    "                current_word = next_word\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize bot\n",
    "    bot = MarkovChatBot()\n",
    "    \n",
    "    # Train the bot with some text data\n",
    "    training_data = \"\"\"\n",
    "    Hello, how are you? I am a chatbot that learns from conversations. You can talk to me about anything. \n",
    "    What do you want to talk about today? I'm happy to help you with your questions!\n",
    "    \"\"\"\n",
    "    \n",
    "    bot.train(training_data)\n",
    "    \n",
    "    # Generate a response\n",
    "    seed_word = \"hello\"\n",
    "    response = bot.generate_response(seed=seed_word, length=20)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a872b1",
   "metadata": {},
   "source": [
    "Second prompt:\n",
    "\n",
    "train it using a series of stories with different characters.\n",
    "\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "To train the Markov chatbot using a series of stories with different characters, you need to feed it text that contains those stories. The chatbot will then build a Markov chain based on the patterns it observes in the stories. Here’s a step-by-step guide to training the chatbot with multiple stories:\n",
    "\n",
    "### 1. Prepare Story Data\n",
    "\n",
    "You can use any stories you like, preferably those that are in text form. For demonstration purposes, let's create some sample stories with different characters.\n",
    "\n",
    "```python\n",
    "# Example stories\n",
    "story_data = \"\"\"\n",
    "Once upon a time, in a small village, there lived a farmer named John. Every morning, John would wake up early \n",
    "and tend to his crops. He loved his farm and worked hard to make sure his animals were happy.\n",
    "\n",
    "In another kingdom far away, a young princess named Eliza dreamed of exploring the world. She would sit by her window, \n",
    "gazing at the horizon, longing for an adventure.\n",
    "\n",
    "One day, John and Eliza met by chance in a bustling market. They quickly became friends and shared their dreams of adventure. \n",
    "Together, they embarked on a journey through forests and mountains, facing challenges and making new friends.\n",
    "\"\"\"\n",
    "\n",
    "# Add another story for diversity\n",
    "more_story_data = \"\"\"\n",
    "In a distant land, there lived a warrior named Marcus. He was brave and strong, feared by his enemies. \n",
    "Despite his tough exterior, Marcus had a kind heart. He would protect the weak and fight for justice.\n",
    "\n",
    "One day, while wandering through the desert, Marcus encountered a merchant who had lost his way. Marcus offered to help, \n",
    "and together, they found the nearest oasis. Grateful, the merchant gave Marcus a rare map that led to a hidden treasure.\n",
    "\n",
    "Meanwhile, in the same land, there was a brilliant inventor named Sophia. She was known for creating marvelous machines. \n",
    "Sophia and Marcus eventually crossed paths, and they teamed up to build incredible inventions that would change the world.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### 2. Train the Chatbot on Multiple Stories\n",
    "\n",
    "Now, we’ll modify the training function to train the chatbot on multiple stories.\n",
    "\n",
    "```python\n",
    "class MarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the Markov chain\n",
    "        self.markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create pairs of consecutive words and populate the Markov chain\n",
    "        for i in range(len(words) - 1):\n",
    "            self.markov_chain[words[i]].append(words[i + 1])\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed word.\n",
    "        \"\"\"\n",
    "        if not seed or seed not in self.markov_chain:\n",
    "            seed = random.choice(list(self.markov_chain.keys()))\n",
    "        \n",
    "        response = [seed]\n",
    "        current_word = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the Markov chain\n",
    "        for _ in range(length - 1):\n",
    "            if current_word in self.markov_chain:\n",
    "                next_word = random.choice(self.markov_chain[current_word])\n",
    "                response.append(next_word)\n",
    "                current_word = next_word\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the bot\n",
    "    bot = MarkovChatBot()\n",
    "    \n",
    "    # Train the bot on multiple stories\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    # Generate a response based on the seed word\n",
    "    seed_word = \"john\"  # Start with a character's name\n",
    "    response = bot.generate_response(seed=seed_word, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n",
    "```\n",
    "\n",
    "### Explanation:\n",
    "1. **Multiple Stories**: We have two different stories with multiple characters (`John`, `Eliza`, `Marcus`, `Sophia`). You can add as many stories as you like, and the bot will train on all of them, identifying patterns.\n",
    "2. **Training the Bot**: We call the `train()` method for each story or batch of text to build a more robust Markov chain.\n",
    "3. **Generating Responses**: When generating responses, the bot will mix language patterns learned from different stories. You can give it a seed word (e.g., a character's name) to steer the response in a particular direction.\n",
    "\n",
    "### Example Response:\n",
    "\n",
    "After training the bot with the stories, running the code might produce output like:\n",
    "\n",
    "```text\n",
    "Bot's response: john would wake up early and tend to his crops. he loved the world. one day, john and eliza dreamed of exploring the map that led to a hidden treasure.\n",
    "```\n",
    "\n",
    "You can extend this further by adding more complex stories and different genres to train the bot for more varied outputs. Would you like to try training the bot with specific stories of your own?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8bde31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example stories\n",
    "story_data = \"\"\"\n",
    "Once upon a time, in a small village, there lived a farmer named John. Every morning, John would wake up early \n",
    "and tend to his crops. He loved his farm and worked hard to make sure his animals were happy.\n",
    "\n",
    "In another kingdom far away, a young princess named Eliza dreamed of exploring the world. She would sit by her window, \n",
    "gazing at the horizon, longing for an adventure.\n",
    "\n",
    "One day, John and Eliza met by chance in a bustling market. They quickly became friends and shared their dreams of adventure. \n",
    "Together, they embarked on a journey through forests and mountains, facing challenges and making new friends.\n",
    "\"\"\"\n",
    "\n",
    "# Add another story for diversity\n",
    "more_story_data = \"\"\"\n",
    "In a distant land, there lived a warrior named Marcus. He was brave and strong, feared by his enemies. \n",
    "Despite his tough exterior, Marcus had a kind heart. He would protect the weak and fight for justice.\n",
    "\n",
    "One day, while wandering through the desert, Marcus encountered a merchant who had lost his way. Marcus offered to help, \n",
    "and together, they found the nearest oasis. Grateful, the merchant gave Marcus a rare map that led to a hidden treasure.\n",
    "\n",
    "Meanwhile, in the same land, there was a brilliant inventor named Sophia. She was known for creating marvelous machines. \n",
    "Sophia and Marcus eventually crossed paths, and they teamed up to build incredible inventions that would change the world.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "866cc52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's response: john every morning john would protect the world she was brave and eliza dreamed of adventure one day john every morning john and worked hard to his animals were happy\n"
     ]
    }
   ],
   "source": [
    "class MarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the Markov chain\n",
    "        self.markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create pairs of consecutive words and populate the Markov chain\n",
    "        for i in range(len(words) - 1):\n",
    "            self.markov_chain[words[i]].append(words[i + 1])\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed word.\n",
    "        \"\"\"\n",
    "        if not seed or seed not in self.markov_chain:\n",
    "            seed = random.choice(list(self.markov_chain.keys()))\n",
    "        \n",
    "        response = [seed]\n",
    "        current_word = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the Markov chain\n",
    "        for _ in range(length - 1):\n",
    "            if current_word in self.markov_chain:\n",
    "                next_word = random.choice(self.markov_chain[current_word])\n",
    "                response.append(next_word)\n",
    "                current_word = next_word\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the bot\n",
    "    bot = MarkovChatBot()\n",
    "    \n",
    "    # Train the bot on multiple stories\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    # Generate a response based on the seed word\n",
    "    seed_word = \"john\"  # Start with a character's name\n",
    "    response = bot.generate_response(seed=seed_word, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a9eb2",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "Prompt:\n",
    "summaries the conversation so far\n",
    "\n",
    "\n",
    "ChatGPT respond: \n",
    "So far, we discussed creating a **Markovian chatbot**. I provided a Python implementation that trains the bot using a text corpus, building a Markov chain to generate probabilistic responses. You then asked about training the chatbot using multiple stories with different characters.\n",
    "\n",
    "I expanded the example by showing how you could train the chatbot on several stories featuring characters like John, Eliza, Marcus, and Sophia. The chatbot learns from these stories and generates responses that mix language patterns from the training data.\n",
    "\n",
    "Link: https://chatgpt.com/share/66ecce3e-bd8c-800d-bb6c-4914ca7ada57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcb2435",
   "metadata": {},
   "source": [
    "***Wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b2fbdf",
   "metadata": {},
   "source": [
    "5. Recreate (or resume) the previous ChatBot session from question \"4\" above, and now prompt the ChatBot session that you have a couple extensions of the code to show it, and then show it each of the extentions of the \"Markovian ChatBot code\" below in turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288027f",
   "metadata": {},
   "source": [
    "(1) Without just supplying your ChatBot session with the answers, see if the ChatBot can figure out what the extensions in the code do; namely, making character specific Markov chains, and using bigrams (rather than just the previous word alone) dependency... prompt your ChatBot session with some hints if it's not seeming to \"get it\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888987c",
   "metadata": {},
   "source": [
    "Prompt: Following from the same Bot, made an extension function where it reads as bigrams, which means the bot not only respond depending on current word but also the one before it. \n",
    "\n",
    "ChatGPT respond: \n",
    "To extend the Markov chatbot to use **bigrams** (where the bot considers the current word and the previous word to generate the next word), we’ll need to modify the training and response generation functions. Here's how to implement that:\n",
    "\n",
    "### Updated Implementation with Bigrams\n",
    "\n",
    "1. **Training with Bigrams**: Instead of just storing transitions for single words, we will store pairs of words.\n",
    "2. **Generating Responses**: The response generation will take into account the last two words to determine the next word.\n",
    "\n",
    "Here’s the updated code:\n",
    "\n",
    "```python\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class BigramMarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the bigram Markov chain\n",
    "        self.bigram_markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the bigram Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create bigrams and populate the Markov chain\n",
    "        for i in range(len(words) - 2):\n",
    "            bigram = (words[i], words[i + 1])\n",
    "            next_word = words[i + 2]\n",
    "            self.bigram_markov_chain[bigram].append(next_word)\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed bigram.\n",
    "        \"\"\"\n",
    "        if not seed:\n",
    "            # Randomly choose a starting bigram from the chain\n",
    "            seed = random.choice(list(self.bigram_markov_chain.keys()))\n",
    "        else:\n",
    "            # Ensure seed is a tuple of two words\n",
    "            seed = tuple(seed.split())\n",
    "\n",
    "        response = list(seed)\n",
    "        current_bigram = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the bigram Markov chain\n",
    "        for _ in range(length - 2):  # We already have 2 words in the response\n",
    "            if current_bigram in self.bigram_markov_chain:\n",
    "                next_word = random.choice(self.bigram_markov_chain[current_bigram])\n",
    "                response.append(next_word)\n",
    "                current_bigram = (current_bigram[1], next_word)  # Move the window\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the bot\n",
    "    bot = BigramMarkovChatBot()\n",
    "    \n",
    "    # Train the bot on multiple stories\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    # Generate a response based on a seed bigram\n",
    "    seed_bigram = \"john and\"  # Start with a bigram from the stories\n",
    "    response = bot.generate_response(seed=seed_bigram, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n",
    "```\n",
    "\n",
    "### Key Changes:\n",
    "1. **Bigrams**: The training function now creates bigrams (pairs of consecutive words) and stores the next word that follows the bigram in the Markov chain.\n",
    "2. **Response Generation**: The response generation takes a tuple of two words (the bigram) and uses it to select the next word from the chain. It shifts the bigram by removing the first word and adding the newly chosen word.\n",
    "\n",
    "### Example Response:\n",
    "\n",
    "With this implementation, the bot will create responses that consider the context provided by the previous word, leading to potentially more coherent and contextually relevant outputs. You can try running the code to see how it generates responses based on bigrams! Would you like to explore further modifications or specific functionalities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6485c439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot's response: john and eliza met by chance in a small village there lived a warrior named marcus he was brave and strong feared by his enemies despite his tough exterior marcus\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class BigramMarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the bigram Markov chain\n",
    "        self.bigram_markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the bigram Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create bigrams and populate the Markov chain\n",
    "        for i in range(len(words) - 2):\n",
    "            bigram = (words[i], words[i + 1])\n",
    "            next_word = words[i + 2]\n",
    "            self.bigram_markov_chain[bigram].append(next_word)\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed bigram.\n",
    "        \"\"\"\n",
    "        if not seed:\n",
    "            # Randomly choose a starting bigram from the chain\n",
    "            seed = random.choice(list(self.bigram_markov_chain.keys()))\n",
    "        else:\n",
    "            # Ensure seed is a tuple of two words\n",
    "            seed = tuple(seed.split())\n",
    "\n",
    "        response = list(seed)\n",
    "        current_bigram = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the bigram Markov chain\n",
    "        for _ in range(length - 2):  # We already have 2 words in the response\n",
    "            if current_bigram in self.bigram_markov_chain:\n",
    "                next_word = random.choice(self.bigram_markov_chain[current_bigram])\n",
    "                response.append(next_word)\n",
    "                current_bigram = (current_bigram[1], next_word)  # Move the window\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the bot\n",
    "    bot = BigramMarkovChatBot()\n",
    "    \n",
    "    # Train the bot on multiple stories\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    # Generate a response based on a seed bigram\n",
    "    seed_bigram = \"john and\"  # Start with a bigram from the stories\n",
    "    response = bot.generate_response(seed=seed_bigram, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f3397",
   "metadata": {},
   "source": [
    "(2) Interact with your ChatBot session to have it explain details of the code wherever you need help understanding what the code is doing and how it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457f5cd",
   "metadata": {},
   "source": [
    "prompt:\n",
    "explain each step and why it is written this way\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "Sure! Let’s break down each step of the **Bigram Markov Chatbot** implementation, explaining the purpose and reasoning behind each part of the code.\n",
    "\n",
    "### 1. Importing Libraries\n",
    "\n",
    "```python\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "```\n",
    "\n",
    "- **random**: Used to make random selections, which is essential for generating responses based on probabilities.\n",
    "- **re**: This library is used for regular expressions, which help in cleaning and processing text (e.g., splitting words).\n",
    "- **defaultdict**: A specialized dictionary that provides default values for non-existent keys. This is useful for our Markov chain, where we want to append words to lists without checking if the key exists.\n",
    "\n",
    "### 2. Defining the Class\n",
    "\n",
    "```python\n",
    "class BigramMarkovChatBot:\n",
    "    def __init__(self):\n",
    "        self.bigram_markov_chain = defaultdict(list)\n",
    "```\n",
    "\n",
    "- **class BigramMarkovChatBot**: Defines a new class for our chatbot.\n",
    "- **self.bigram_markov_chain = defaultdict(list)**: Initializes an empty Markov chain that will store bigrams as keys (tuples of two words) and lists of possible following words as values.\n",
    "\n",
    "### 3. Training the Bot\n",
    "\n",
    "```python\n",
    "def train(self, text):\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "```\n",
    "\n",
    "- **def train(self, text)**: Defines a method to train the chatbot using the provided text.\n",
    "- **re.findall(r'\\b\\w+\\b', text.lower())**: Cleans the input text by converting it to lowercase and extracting words using regular expressions. This helps in standardizing the text for training.\n",
    "\n",
    "### 4. Creating Bigrams\n",
    "\n",
    "```python\n",
    "for i in range(len(words) - 2):\n",
    "    bigram = (words[i], words[i + 1])\n",
    "    next_word = words[i + 2]\n",
    "    self.bigram_markov_chain[bigram].append(next_word)\n",
    "```\n",
    "\n",
    "- **for i in range(len(words) - 2)**: Loops through the words to form bigrams. We go up to `len(words) - 2` to avoid index errors when accessing the next word.\n",
    "- **bigram = (words[i], words[i + 1])**: Creates a tuple representing the current bigram (the current word and the next word).\n",
    "- **next_word = words[i + 2]**: Identifies the word that follows the bigram.\n",
    "- **self.bigram_markov_chain[bigram].append(next_word)**: Appends the next word to the list corresponding to the bigram in the Markov chain.\n",
    "\n",
    "### 5. Generating Responses\n",
    "\n",
    "```python\n",
    "def generate_response(self, seed=None, length=15):\n",
    "    if not seed:\n",
    "        seed = random.choice(list(self.bigram_markov_chain.keys()))\n",
    "    else:\n",
    "        seed = tuple(seed.split())\n",
    "```\n",
    "\n",
    "- **def generate_response(self, seed=None, length=15)**: Defines a method to generate a response, with an optional seed bigram and a specified response length.\n",
    "- **if not seed**: Checks if a seed bigram is provided; if not, it randomly selects one from the keys of the Markov chain.\n",
    "- **seed = tuple(seed.split())**: Converts the seed string into a tuple (bigram format) if a seed is provided.\n",
    "\n",
    "### 6. Building the Response\n",
    "\n",
    "```python\n",
    "response = list(seed)\n",
    "current_bigram = seed\n",
    "```\n",
    "\n",
    "- **response = list(seed)**: Initializes the response list with the seed bigram.\n",
    "- **current_bigram = seed**: Sets the current bigram to the initial seed, which will be updated as we generate the response.\n",
    "\n",
    "### 7. Selecting Words Based on Bigrams\n",
    "\n",
    "```python\n",
    "for _ in range(length - 2):  # We already have 2 words in the response\n",
    "    if current_bigram in self.bigram_markov_chain:\n",
    "        next_word = random.choice(self.bigram_markov_chain[current_bigram])\n",
    "        response.append(next_word)\n",
    "        current_bigram = (current_bigram[1], next_word)  # Move the window\n",
    "    else:\n",
    "        break\n",
    "```\n",
    "\n",
    "- **for _ in range(length - 2)**: Loops to add words to the response, ensuring the total length matches the desired response length.\n",
    "- **if current_bigram in self.bigram_markov_chain**: Checks if the current bigram exists in the Markov chain.\n",
    "- **next_word = random.choice(self.bigram_markov_chain[current_bigram])**: Randomly selects the next word based on the current bigram.\n",
    "- **response.append(next_word)**: Adds the selected word to the response list.\n",
    "- **current_bigram = (current_bigram[1], next_word)**: Updates the current bigram by removing the first word and adding the newly chosen word, effectively \"shifting\" the window for the next iteration.\n",
    "\n",
    "### 8. Returning the Response\n",
    "\n",
    "```python\n",
    "return ' '.join(response)\n",
    "```\n",
    "\n",
    "- **return ' '.join(response)**: Joins the list of words into a single string and returns it as the final response.\n",
    "\n",
    "### 9. Example Usage\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    bot = BigramMarkovChatBot()\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    seed_bigram = \"john and\"  # Start with a bigram from the stories\n",
    "    response = bot.generate_response(seed=seed_bigram, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n",
    "```\n",
    "\n",
    "- This section demonstrates how to use the bot by creating an instance, training it with story data, and generating a response based on a specified bigram.\n",
    "\n",
    "### Summary\n",
    "This implementation enhances the chatbot's ability to generate coherent responses by considering the context of the previous word, thus creating a more nuanced output. The use of bigrams allows the chatbot to capture the relationships between words more effectively, leading to responses that are more contextually relevant and fluid. If you have any more questions or would like further modifications, let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938c40c9",
   "metadata": {},
   "source": [
    "Summary:\n",
    "prompt: summaries our conversation so far\n",
    "\n",
    "ChatGPT respond:\n",
    "In our conversation, we discussed creating a **Markovian chatbot** in Python. Initially, I provided a basic implementation that used single words to generate responses. You then requested an extension to train the bot using multiple stories with different characters, which I demonstrated.\n",
    "\n",
    "Next, you asked to enhance the chatbot to use **bigrams**, where the bot considers both the current and previous words when generating responses. I explained the necessary modifications to the code, detailing how to create a bigram Markov chain and generate responses based on bigrams. Finally, I broke down each step of the implementation to explain the reasoning behind the code structure and functionality.\n",
    "\n",
    "Link: https://chatgpt.com/share/66ecce3e-bd8c-800d-bb6c-4914ca7ada57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c10b4",
   "metadata": {},
   "source": [
    "(3)\n",
    "Start yet another new ChatBot session and first show the ChatBot the original \"Markovian ChatBot code\" below, and then tell ChatBot that you have an extension but this time just directly provide it the more complicated final extension without ever providing the intermediate extension code to the ChatBot session and see if it's still able to understand everything extension does; namely, making character specific Markov chains, and using bigrams (rather than just the previous word alone) dependency... prompt the ChatBot with some hints if it's not seeming to understand what you're getting at..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f5deb",
   "metadata": {},
   "source": [
    "prompt: \n",
    "    see the following code and explain step by step how the code works: import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class BigramMarkovChatBot:\n",
    "    def __init__(self):\n",
    "        # Dictionary to store the bigram Markov chain\n",
    "        self.bigram_markov_chain = defaultdict(list)\n",
    "        \n",
    "    def train(self, text):\n",
    "        \"\"\"\n",
    "        Train the bot with input text. The text will be processed into the bigram Markov chain.\n",
    "        \"\"\"\n",
    "        # Clean and split the text into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        \n",
    "        # Create bigrams and populate the Markov chain\n",
    "        for i in range(len(words) - 2):\n",
    "            bigram = (words[i], words[i + 1])\n",
    "            next_word = words[i + 2]\n",
    "            self.bigram_markov_chain[bigram].append(next_word)\n",
    "    \n",
    "    def generate_response(self, seed=None, length=15):\n",
    "        \"\"\"\n",
    "        Generate a response of a given length starting from a seed bigram.\n",
    "        \"\"\"\n",
    "        if not seed:\n",
    "            # Randomly choose a starting bigram from the chain\n",
    "            seed = random.choice(list(self.bigram_markov_chain.keys()))\n",
    "        else:\n",
    "            # Ensure seed is a tuple of two words\n",
    "            seed = tuple(seed.split())\n",
    "\n",
    "        response = list(seed)\n",
    "        current_bigram = seed\n",
    "        \n",
    "        # Build the response by picking random words based on the bigram Markov chain\n",
    "        for _ in range(length - 2):  # We already have 2 words in the response\n",
    "            if current_bigram in self.bigram_markov_chain:\n",
    "                next_word = random.choice(self.bigram_markov_chain[current_bigram])\n",
    "                response.append(next_word)\n",
    "                current_bigram = (current_bigram[1], next_word)  # Move the window\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the bot\n",
    "    bot = BigramMarkovChatBot()\n",
    "    \n",
    "    # Train the bot on multiple stories\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    # Generate a response based on a seed bigram\n",
    "    seed_bigram = \"john and\"  # Start with a bigram from the stories\n",
    "    response = bot.generate_response(seed=seed_bigram, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n",
    "\n",
    "ChatGPT respond: \n",
    "This code defines a chatbot that uses a **Bigram Markov Model** to generate text responses based on training data. Let me break it down step by step:\n",
    "\n",
    "### 1. Importing Libraries\n",
    "```python\n",
    "import random\n",
    "import re\n",
    "from collections import defaultdict\n",
    "```\n",
    "- **random**: Used to make random selections, especially for generating responses.\n",
    "- **re**: Provides regular expressions to process text (splitting into words).\n",
    "- **defaultdict**: From the `collections` module, it's used to automatically initialize missing keys in a dictionary with a default value, here, an empty list.\n",
    "\n",
    "### 2. Class Definition: `BigramMarkovChatBot`\n",
    "This class defines the chatbot itself.\n",
    "\n",
    "#### `__init__` Method\n",
    "```python\n",
    "def __init__(self):\n",
    "    # Dictionary to store the bigram Markov chain\n",
    "    self.bigram_markov_chain = defaultdict(list)\n",
    "```\n",
    "- **Purpose**: The constructor initializes an empty Markov chain, where the key will be a **bigram** (two consecutive words), and the value will be a list of possible words that follow this bigram.\n",
    "- The `defaultdict(list)` ensures that whenever a key (bigram) is accessed for the first time, it initializes an empty list automatically.\n",
    "\n",
    "#### `train` Method\n",
    "```python\n",
    "def train(self, text):\n",
    "    # Clean and split the text into words\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    \n",
    "    # Create bigrams and populate the Markov chain\n",
    "    for i in range(len(words) - 2):\n",
    "        bigram = (words[i], words[i + 1])\n",
    "        next_word = words[i + 2]\n",
    "        self.bigram_markov_chain[bigram].append(next_word)\n",
    "```\n",
    "- **Purpose**: This method trains the chatbot by processing text and creating bigrams.\n",
    "  \n",
    "  Steps:\n",
    "  1. **Text Cleaning and Splitting**:\n",
    "     - `re.findall(r'\\b\\w+\\b', text.lower())`:\n",
    "       - `\\b\\w+\\b` is a regex pattern that matches individual words (sequences of alphanumeric characters).\n",
    "       - `text.lower()` ensures all words are in lowercase, for consistency.\n",
    "  \n",
    "  2. **Generating Bigrams**:\n",
    "     - For each bigram (pair of consecutive words), the next word is noted and added to the list of possible following words in the `bigram_markov_chain`.\n",
    "     - `bigram = (words[i], words[i + 1])`: The bigram consists of two consecutive words.\n",
    "     - `next_word = words[i + 2]`: The next word that follows the bigram is stored.\n",
    "     - `self.bigram_markov_chain[bigram].append(next_word)`: This line updates the Markov chain, associating the bigram with the following word.\n",
    "\n",
    "#### `generate_response` Method\n",
    "```python\n",
    "def generate_response(self, seed=None, length=15):\n",
    "    if not seed:\n",
    "        # Randomly choose a starting bigram from the chain\n",
    "        seed = random.choice(list(self.bigram_markov_chain.keys()))\n",
    "    else:\n",
    "        # Ensure seed is a tuple of two words\n",
    "        seed = tuple(seed.split())\n",
    "\n",
    "    response = list(seed)\n",
    "    current_bigram = seed\n",
    "    \n",
    "    # Build the response by picking random words based on the bigram Markov chain\n",
    "    for _ in range(length - 2):  # We already have 2 words in the response\n",
    "        if current_bigram in self.bigram_markov_chain:\n",
    "            next_word = random.choice(self.bigram_markov_chain[current_bigram])\n",
    "            response.append(next_word)\n",
    "            current_bigram = (current_bigram[1], next_word)  # Move the window\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return ' '.join(response)\n",
    "```\n",
    "- **Purpose**: This method generates a response based on the trained Markov chain.\n",
    "\n",
    "  Steps:\n",
    "  1. **Choosing a Seed**:\n",
    "     - If no seed bigram is provided (`seed=None`), the bot randomly selects one from the `bigram_markov_chain`.\n",
    "     - If a seed is provided, it's converted into a tuple of two words: `tuple(seed.split())`.\n",
    "  \n",
    "  2. **Initializing the Response**:\n",
    "     - `response = list(seed)`: The response starts with the two words from the seed bigram.\n",
    "     - `current_bigram = seed`: The current bigram starts as the seed.\n",
    "\n",
    "  3. **Generating the Response**:\n",
    "     - The bot constructs the response word by word, using the Markov chain to pick a random word that follows the current bigram.\n",
    "     - It updates `current_bigram` by shifting to the next pair: `(current_bigram[1], next_word)`.\n",
    "\n",
    "     This process continues until the response reaches the specified length or the bigram has no following word in the chain.\n",
    "  \n",
    "  4. **Returning the Response**:\n",
    "     - Once the loop completes, the list `response` is joined into a single string and returned.\n",
    "\n",
    "#### Example Usage\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the bot\n",
    "    bot = BigramMarkovChatBot()\n",
    "    \n",
    "    # Train the bot on multiple stories\n",
    "    bot.train(story_data)\n",
    "    bot.train(more_story_data)\n",
    "    \n",
    "    # Generate a response based on a seed bigram\n",
    "    seed_bigram = \"john and\"  # Start with a bigram from the stories\n",
    "    response = bot.generate_response(seed=seed_bigram, length=30)\n",
    "    \n",
    "    print(\"Bot's response:\", response)\n",
    "```\n",
    "- **Training**: The bot is trained with multiple text sources like `story_data` and `more_story_data` (these would be defined somewhere in the code).\n",
    "- **Generating Response**: The bot generates a response starting with the seed bigram `\"john and\"` and continues generating words until the response is 30 words long.\n",
    "\n",
    "### Summary:\n",
    "- The bot learns patterns of word sequences (bigrams) from the input text.\n",
    "- It then uses these patterns to generate coherent responses, starting from either a random bigram or a provided one.\n",
    "\n",
    "Link: https://chatgpt.com/share/66ecdad8-0efc-800d-a6bf-f801597b2594"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809693f",
   "metadata": {},
   "source": [
    "*** Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220bc548",
   "metadata": {},
   "source": [
    "4. Watch the embedded video tutorial on Markov chains in the next Jupyter cell below to understand their application and relevance for ChatBots; then, after watching the video, start a new ChatBot session by prompting that you have code that creates a \"Markovian ChatBot\"; show it the first version of the \"Markovian ChatBot code\" below; and interact with the ChatBot session to make sure you understand how the original first version of the \"Markovian ChatBot code\" works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7498a8c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m word_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m() \u001b[38;5;66;03m# defaultdict(int)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m next_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m() \u001b[38;5;66;03m# defaultdict(lambda: defaultdict(int))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mwords\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_used:\n\u001b[1;32m      9\u001b[0m         word_used[word] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "# Markovian Chatbot\n",
    "\n",
    "# from collections import defaultdict\n",
    "word_used = dict() # defaultdict(int)\n",
    "next_word = dict() # defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-1]):\n",
    "\n",
    "    if word in word_used:\n",
    "        word_used[word] += 1\n",
    "    else:\n",
    "        word_used[word] = 1\n",
    "        next_word[word] = {}\n",
    "\n",
    "    if words[i+1] in next_word[word]:\n",
    "        next_word[word][words[i+1]] += 1\n",
    "    else:\n",
    "        next_word[word][words[i+1]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b53e6cc",
   "metadata": {},
   "source": [
    "prompt: \n",
    "\n",
    "How does this code works: # Markovian Chatbot\n",
    "\n",
    "# from collections import defaultdict\n",
    "word_used = dict() # defaultdict(int)\n",
    "next_word = dict() # defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-1]):\n",
    "\n",
    "    if word in word_used:\n",
    "        word_used[word] += 1\n",
    "    else:\n",
    "        word_used[word] = 1\n",
    "        next_word[word] = {}\n",
    "\n",
    "    if words[i+1] in next_word[word]:\n",
    "        next_word[word][words[i+1]] += 1\n",
    "    else:\n",
    "        next_word[word][words[i+1]] = 1\n",
    "        \n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "This code snippet is part of a simple Markovian chatbot that uses a Markov chain to generate text based on word sequences. Here’s a breakdown of how it works:\n",
    "\n",
    "1. **Initialization**:\n",
    "   - `word_used`: A dictionary that counts how many times each word has been seen.\n",
    "   - `next_word`: A nested dictionary where each key is a word, and the value is another dictionary that counts how many times each subsequent word follows it.\n",
    "\n",
    "2. **Iterating through Words**:\n",
    "   - The loop goes through the list of `words`, stopping before the last word (`words[:-1]`) to avoid index errors.\n",
    "   - For each word in the list:\n",
    "     - It checks if the word is already in `word_used`:\n",
    "       - If yes, it increments the count.\n",
    "       - If no, it initializes the count to 1 and sets up an empty dictionary for `next_word[word]`.\n",
    "     - Then it looks at the next word (`words[i+1]`):\n",
    "       - If this next word is already a key in `next_word[word]`, it increments its count.\n",
    "       - If not, it initializes its count to 1.\n",
    "\n",
    "3. **Purpose**:\n",
    "   - The `word_used` dictionary keeps track of how often each word appears in the input.\n",
    "   - The `next_word` dictionary builds a frequency distribution of which words follow which, allowing the chatbot to predict the next word based on the current word.\n",
    "\n",
    "This code is foundational for creating a simple text generation model where the next word is chosen based on the probability of it following the current word in the training data. To generate text, you would use these dictionaries to randomly select the next word based on the counts recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109fde1",
   "metadata": {},
   "source": [
    "Summary\n",
    "Prompt: provide the summary of the conversation\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "In this conversation, you asked about a code snippet for a Markovian chatbot. I explained how the code works, detailing the initialization of two dictionaries: `word_used`, which counts occurrences of words, and `next_word`, which tracks how many times each word is followed by other words. I also described how the code iterates through a list of words to populate these dictionaries, emphasizing the purpose of predicting the next word based on word frequencies.\n",
    "\n",
    "Link: https://chatgpt.com/share/66ece975-b958-800d-a90f-744c0d1a4950\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1199d",
   "metadata": {},
   "source": [
    "5. Recreate (or resume) the previous ChatBot session from question \"4\" above, and now prompt the ChatBot session that you have a couple extensions of the code to show it, and then show it each of the extentions of the \"Markovian ChatBot code\" below in turn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078edba7",
   "metadata": {},
   "source": [
    "(1) Without just supplying your ChatBot session with the answers, see if the ChatBot can figure out what the extensions in the code do; namely, making character specific Markov chains, and using bigrams (rather than just the previous word alone) dependency... prompt your ChatBot session with some hints if it's not seeming to \"get it\"\n",
    "prompt: what is this extension doing in regard to the above chatbot:\n",
    "\n",
    "\n",
    "# Markovian Chatbot Extension #1\n",
    "\n",
    "word_used2 = defaultdict(int)\n",
    "next_word2 = defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-2]):\n",
    "    word_used2[word+' '+words[i+1]] += 1\n",
    "    next_word2[word+' '+words[i+1]][words[i+2]] += 1 \n",
    "    \n",
    "ChatGPT respond:\n",
    "This extension of the Markovian chatbot introduces a higher-order Markov chain by considering sequences of two words instead of just one. Here’s how it works:\n",
    "\n",
    "1. **Initialization**:\n",
    "   - `word_used2`: A `defaultdict` that counts how many times each two-word sequence (bigram) appears.\n",
    "   - `next_word2`: A nested `defaultdict` where each key is a two-word sequence, and the value is another `defaultdict` that counts how many times each subsequent word follows that sequence.\n",
    "\n",
    "2. **Iterating through Words**:\n",
    "   - The loop iterates through the list of `words`, stopping before the last two words (`words[:-2]`) to avoid index errors.\n",
    "   - For each word at index `i`, it forms a two-word sequence by combining the current word and the next word (`word + ' ' + words[i+1]`).\n",
    "   - It increments the count for this two-word sequence in `word_used2`.\n",
    "   - It then updates `next_word2` by incrementing the count for the word that follows the two-word sequence (i.e., `words[i+2]`).\n",
    "\n",
    "3. **Purpose**:\n",
    "   - By using bigrams (two-word sequences), the chatbot can capture more contextual information compared to the original implementation that only considered single words.\n",
    "   - This allows for more coherent text generation, as the model can account for the relationship between pairs of words when predicting the next word.\n",
    "\n",
    "Overall, this extension enhances the chatbot's ability to generate more contextually relevant responses by leveraging sequences of words instead of treating each word in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1236f12b",
   "metadata": {},
   "source": [
    "(2) Interact with your ChatBot session to have it explain details of the code wherever you need help understanding what the code is doing and how it works\n",
    "\n",
    "prompt:\n",
    "can you explain more detail of the chatbot and the extension\n",
    "\n",
    "\n",
    "\n",
    "ChatGPT respond: \n",
    "Sure! Let’s dive deeper into both the original Markovian chatbot and the extension, focusing on their structure and functionality.\n",
    "\n",
    "### Original Markovian Chatbot\n",
    "\n",
    "**Concept**:\n",
    "The original chatbot is based on a first-order Markov chain, which means it predicts the next state (word) based only on the current state (word). The key idea is that the probability of each word occurring depends only on the previous word.\n",
    "\n",
    "**Components**:\n",
    "1. **Data Structures**:\n",
    "   - **`word_used`**: A dictionary that counts the occurrences of each word.\n",
    "     - **Purpose**: Helps in understanding the frequency of individual words in the training data.\n",
    "   - **`next_word`**: A nested dictionary that maps each word to another dictionary of words that can follow it, along with their counts.\n",
    "     - **Purpose**: Allows the chatbot to know which words are likely to follow a given word, forming a basis for text generation.\n",
    "\n",
    "2. **Process**:\n",
    "   - The loop iterates through a list of words.\n",
    "   - For each word, it updates `word_used` to keep track of how many times that word has been encountered.\n",
    "   - It also updates `next_word` to count how often each subsequent word appears after the current word.\n",
    "   - This information can later be used to generate text by sampling the next word based on the counts stored.\n",
    "\n",
    "**Text Generation**:\n",
    "- To generate text, the chatbot starts with a word and repeatedly selects the next word based on the frequency of words that follow the current word. This can be done using random selection weighted by the counts in `next_word`.\n",
    "\n",
    "### Extension: Markovian Chatbot Extension #1\n",
    "\n",
    "**Concept**:\n",
    "This extension introduces a second-order Markov chain, which means it predicts the next word based on the two most recent words. This provides more context and can lead to more coherent and contextually relevant outputs.\n",
    "\n",
    "**Components**:\n",
    "1. **Data Structures**:\n",
    "   - **`word_used2`**: A `defaultdict` that counts occurrences of two-word sequences (bigrams).\n",
    "     - **Purpose**: Tracks how often each two-word combination appears, allowing for better contextual understanding.\n",
    "   - **`next_word2`**: A nested `defaultdict` that maps each two-word sequence to another dictionary of words that can follow it, along with their counts.\n",
    "     - **Purpose**: Captures the relationship between pairs of words and the words that follow them.\n",
    "\n",
    "2. **Process**:\n",
    "   - The loop iterates through the list of words, stopping before the last two words.\n",
    "   - For each index `i`, it forms a two-word sequence by concatenating the current word and the next word (`word + ' ' + words[i+1]`).\n",
    "   - It increments the count for this two-word sequence in `word_used2`.\n",
    "   - It updates `next_word2` by counting how often the word that follows the two-word sequence appears (i.e., `words[i+2]`).\n",
    "\n",
    "**Text Generation**:\n",
    "- When generating text, the chatbot uses the last two words as context to predict the next word. This allows it to maintain better context over longer sequences, resulting in more fluent and meaningful text.\n",
    "\n",
    "### Summary of Benefits\n",
    "- **Original Chatbot**: Simpler and faster but may produce less coherent sentences due to lack of context.\n",
    "- **Extension**: More complex and memory-intensive but leads to more natural and relevant text generation by considering the relationships between pairs of words.\n",
    "\n",
    "Overall, both the original and the extended chatbot can be useful for different applications, depending on the level of coherence and contextuality required for the generated text.\n",
    "\n",
    "\n",
    "Prompt: provide a summary for all the conversation\n",
    "\n",
    "ChatGPT respond:\n",
    "In this conversation, you first inquired about a code snippet for a Markovian chatbot, and I explained how it initializes two dictionaries—`word_used` for counting word occurrences and `next_word` for tracking which words follow others. I also described how the chatbot predicts the next word based on these counts.\n",
    "\n",
    "Next, you asked about an extension of the chatbot that incorporates a second-order Markov chain, which considers two-word sequences (bigrams). I detailed how this extension initializes new dictionaries—`word_used2` and `next_word2`—to count bigram occurrences and the words that follow them. I highlighted the benefits of using bigrams for generating more coherent and contextually relevant text compared to the original implementation.\n",
    "\n",
    "Finally, I provided a comprehensive breakdown of both the original chatbot and its extension, summarizing their concepts, components, processes, and benefits.\n",
    "\n",
    "\n",
    "Link: https://chatgpt.com/share/66ece975-b958-800d-a90f-744c0d1a4950\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c7580",
   "metadata": {},
   "source": [
    "(3) Start yet another new ChatBot session and first show the ChatBot the original \"Markovian ChatBot code\" below, and then tell ChatBot that you have an extension but this time just directly provide it the more complicated final extension without ever providing the intermediate extension code to the ChatBot session and see if it's still able to understand everything extension does; namely, making character specific Markov chains, and using bigrams (rather than just the previous word alone) dependency... prompt the ChatBot with some hints if it's not seeming to understand what you're getting at...\n",
    "\n",
    "prompt: see and explain the following chatbot code: # Markovian Chatbot\n",
    "\n",
    "# from collections import defaultdict\n",
    "word_used = dict() # defaultdict(int)\n",
    "next_word = dict() # defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-1]):\n",
    "\n",
    "    if word in word_used:\n",
    "        word_used[word] += 1\n",
    "    else:\n",
    "        word_used[word] = 1\n",
    "        next_word[word] = {}\n",
    "\n",
    "    if words[i+1] in next_word[word]:\n",
    "        next_word[word][words[i+1]] += 1\n",
    "    else:\n",
    "        next_word[word][words[i+1]] = 1\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "This code snippet is part of a simple Markovian chatbot that uses word frequency to generate responses based on previous words. Let’s break it down step by step:\n",
    "\n",
    "1. **Imports**: \n",
    "   - The code mentions `defaultdict` from the `collections` module, but it’s commented out. The code instead uses regular dictionaries, which is fine but less efficient for counting.\n",
    "\n",
    "2. **Dictionaries Initialization**:\n",
    "   - `word_used`: This dictionary keeps track of how many times each word appears in the input text.\n",
    "   - `next_word`: This dictionary maps each word to another dictionary that tracks the frequency of words that follow it.\n",
    "\n",
    "3. **Iterating Over Words**:\n",
    "   - The `for` loop iterates through a list of words (`words`), except for the last one (`words[:-1]`), since it looks at pairs of words.\n",
    "   - `enumerate` is used to get both the index (`i`) and the word (`word`) at that index.\n",
    "\n",
    "4. **Counting Word Frequencies**:\n",
    "   - For each word in `words`:\n",
    "     - If the word has already been encountered (exists in `word_used`), its count is incremented.\n",
    "     - If it’s the first time the word is seen, it initializes its count to 1 and creates an entry in `next_word`.\n",
    "\n",
    "5. **Tracking Next Words**:\n",
    "   - The next word in the sequence (`words[i+1]`) is checked:\n",
    "     - If it follows the current word in `next_word`, its count is incremented.\n",
    "     - If it’s the first time this next word has been encountered after the current word, it initializes its count to 1.\n",
    "\n",
    "### Summary\n",
    "- **Purpose**: The code builds a basic statistical model of how words follow one another based on input data.\n",
    "- **Use Case**: In a chatbot context, when generating a response, the chatbot could randomly select a starting word and then use the `next_word` dictionary to pick subsequent words based on their frequencies, creating a response that feels somewhat natural and coherent. \n",
    "\n",
    "This approach leverages the Markov property, where the next state (or word) depends only on the current state (or word) and not on the sequence of events that preceded it.\n",
    "\n",
    "\n",
    "\n",
    "prompt2: \n",
    "see and explain the following extension step by step: # Markovian Chatbot Extension #2\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "# avatar is a dataset, and character is one of it's columns\n",
    "characters = Counter(\"\\n\"+ avatar.character.str.upper().str.replace(' ','.')+\":\")\n",
    "# this code changes the type of the character column to str; then,\n",
    "# makes the text uppercase, and replaces spaces with '.'\n",
    "\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "word_used2C = nested_dict()\n",
    "next_word2C = nested_dict()\n",
    "\n",
    "for i,word in enumerate(words[:-2]):\n",
    "    if word in characters:\n",
    "        character = word\n",
    "        \n",
    "    if character not in word_used2C:\n",
    "        word_used2C[character] = dict()\n",
    "    if word+' '+words[i+1] not in word_used2C[character]:\n",
    "        word_used2C[character][word+' '+words[i+1]] = 0\n",
    "    word_used2C[character][word+' '+words[i+1]] += 1\n",
    "    \n",
    "    if character not in next_word2C:\n",
    "        next_word2C[character] = dict()\n",
    "    if word+' '+words[i+1] not in next_word2C[character]:\n",
    "        next_word2C[character][word+' '+words[i+1]] = dict()\n",
    "    if words[i+2] not in next_word2C[character][word+' '+words[i+1]]:\n",
    "        next_word2C[character][word+' '+words[i+1]][words[i+2]] = 0\n",
    "    next_word2C[character][word+' '+words[i+1]][words[i+2]] += 1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "This extension of the Markovian chatbot code introduces more complexity by organizing the data based on character dialogue, allowing for character-specific responses. Let's break it down step by step:\n",
    "\n",
    "### 1. Imports\n",
    "```python\n",
    "from collections import Counter, defaultdict\n",
    "```\n",
    "- `Counter`: A dictionary subclass for counting hashable objects.\n",
    "- `defaultdict`: A dictionary that provides a default value for non-existent keys, which simplifies counting and nested dictionary creation.\n",
    "\n",
    "### 2. Data Preparation\n",
    "```python\n",
    "characters = Counter(\"\\n\" + avatar.character.str.upper().str.replace(' ', '.') + \":\")\n",
    "```\n",
    "- This line processes a column (`character`) from a dataset (`avatar`):\n",
    "  - It converts all characters' names to uppercase.\n",
    "  - It replaces spaces with dots to standardize names (e.g., \"John Doe\" becomes \"JOHN.DOE\").\n",
    "  - It prefixes each name with a newline character and appends a colon, creating a unique identifier for each character.\n",
    "\n",
    "### 3. Nested Dictionary Initialization\n",
    "```python\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "word_used2C = nested_dict()\n",
    "next_word2C = nested_dict()\n",
    "```\n",
    "- `nested_dict`: A recursive lambda function that creates a nested `defaultdict`, allowing for multiple levels of keys (e.g., character → phrases → next words).\n",
    "- `word_used2C`: This will track word usage per character.\n",
    "- `next_word2C`: This will track which words follow a given phrase for each character.\n",
    "\n",
    "### 4. Iterating Over Words\n",
    "```python\n",
    "for i, word in enumerate(words[:-2]):\n",
    "```\n",
    "- The loop iterates over `words`, except for the last two (`words[:-2]`), to prevent index errors when checking for subsequent words.\n",
    "\n",
    "### 5. Character Recognition and Word Counting\n",
    "```python\n",
    "if word in characters:\n",
    "    character = word\n",
    "```\n",
    "- If the current word matches a character in the `characters` Counter, it assigns that word to `character`.\n",
    "\n",
    "#### Word Usage Count\n",
    "```python\n",
    "if character not in word_used2C:\n",
    "    word_used2C[character] = dict()\n",
    "if word + ' ' + words[i + 1] not in word_used2C[character]:\n",
    "    word_used2C[character][word + ' ' + words[i + 1]] = 0\n",
    "word_used2C[character][word + ' ' + words[i + 1]] += 1\n",
    "```\n",
    "- This block counts occurrences of phrases (current word + next word) for each character.\n",
    "- It initializes the count for a phrase if it hasn't been seen before, then increments the count.\n",
    "\n",
    "### 6. Next Word Tracking\n",
    "```python\n",
    "if character not in next_word2C:\n",
    "    next_word2C[character] = dict()\n",
    "if word + ' ' + words[i + 1] not in next_word2C[character]:\n",
    "    next_word2C[character][word + ' ' + words[i + 1]] = dict()\n",
    "if words[i + 2] not in next_word2C[character][word + ' ' + words[i + 1]]:\n",
    "    next_word2C[character][word + ' ' + words[i + 1]][words[i + 2]] = 0\n",
    "next_word2C[character][word + ' ' + words[i + 1]][words[i + 2]] += 1\n",
    "```\n",
    "- Similar to word usage, this block tracks the next word that follows a specific phrase for each character.\n",
    "- It initializes nested dictionaries for character and phrase combinations, and increments the count for the next word.\n",
    "\n",
    "### Summary\n",
    "- **Purpose**: This code extends the chatbot's capabilities to handle multiple characters by organizing dialogue data.\n",
    "- **Data Structure**: The use of nested dictionaries allows for tracking phrases and the words that follow them, tailored to specific characters.\n",
    "- **Outcome**: This structure enables the chatbot to generate responses based on the character's dialogue style, enhancing interactivity and realism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b42f09",
   "metadata": {},
   "source": [
    "Summary:\n",
    "prompt: \n",
    "\n",
    "summarize the conversation\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "We discussed two pieces of code related to a Markovian chatbot. \n",
    "\n",
    "1. **First Code Snippet**: This simple chatbot uses dictionaries to track word frequencies and the words that follow them. It builds a statistical model based on input text, allowing the bot to generate responses by selecting words based on their preceding context.\n",
    "\n",
    "2. **Second Code Snippet (Extension)**: This extension organizes data by character, enabling character-specific dialogue. It utilizes `Counter` to process character names and nested `defaultdicts` to count word usage and track subsequent words for phrases associated with each character. This enhances the chatbot's ability to produce responses that match the dialogue style of specific characters.\n",
    "\n",
    "Overall, both snippets demonstrate the use of the Markov property to generate text, with the second adding complexity for character-specific interactions.\n",
    "\n",
    "Link: https://chatgpt.com/share/66ecebf3-0904-800d-a36d-690b399de0d5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf0bce0",
   "metadata": {},
   "source": [
    "6. Report on your experience interacting with ChatBots to understand the Monte Hall problem and \"Markovian ChatBot\" code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c8cb8",
   "metadata": {},
   "source": [
    "(1) Discuss how quickly the ChatBot was able to be helpful for each of the above questions, and if so, how?\n",
    "\n",
    "When ChatGPT is helping me with Monte Hall Problem, it seems very quick and smooth, I can generate my prompt quickly and ChatGPT was able to answere and generate the output I want to know and see. In contrast, in Markovian ChatBot, I struggled more in generating prompts. Additionally, the idea of Markovian ChatBot seems to be more complicated to ChatGPT considering the run time is visibly longer than Monte Hall Problem and the respond from ChatGPT in regard to Markovian ChatBot is also longer than the Monte Hall Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f39671",
   "metadata": {},
   "source": [
    "(2) Discuss whether or not interacting with ChatBot to try to figure things out was frustrating or unhelpful, and if so, how?\n",
    "\n",
    "It definitely helped a lot in understanding how the logic flow and how the code works. Rather than read the code line by line and input different variables by myself to see how the program works, by using ChatGPT made the entire process of understanding easier and faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a6e300",
   "metadata": {},
   "source": [
    "(3) Based on your experiences to date (e.g., including using ChatBots to troubleshoot coding errors in the previous homework), provide an overall assessment evaluating the usefulness of ChatBots as tools to help you understand code\n",
    "\n",
    "ChatGPT is extremely helpful when it comes to resovling errors and mistakes including the ones in your programs. Additionally, when it comes to the assignment in this course, the description is way too long to understand what the questions are asking about, on that end, ChatGPT also helped a lot in terms of understanding what exactly my tasks are other than just help with coding, breakdown programs step by step, or debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc00b7",
   "metadata": {},
   "source": [
    "7. Reflect on your experience interacting with ChatBot and describe how your perception of AI-driven assistance tools in the context of learning coding, statistics, and data science has been evolving (or not) since joining the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e21386",
   "metadata": {},
   "source": [
    "My perception of AI-powered support tools significantly changed in this course: from a ChatBot being generally perceived as a kind of reference source that would be helpful but because the mindset of using AI tools in university will caused serious problem so I never think of their depth-providing information or working with them on the most cutting-edge subjects, such as the Monte Hall problem and writing \"Markovian ChatBot\" code. I came to think of them. However, as valuable learning partners: They extend the conventional resources by providing interactivity and adaptability to my questions. While they extend and benefit my understanding, I also realize their limitations which at times also provide information that is beyond what is required or faulty information. Overall, I have learned to think about ChatBots as an important part of my learning tool which helps a lot in integrating all the knowledge and notion in coding, statistics, data science, etc. while considering the balance between self-learning skills and the implement of AI tools so I'm still rigorously learning and consuming new knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a0280b",
   "metadata": {},
   "source": [
    "8. ChatBots consume text data available on the web or platforms, and thus represents a new way to \"search consensensus\" that condenses and summarizes mainstream human thought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c394c",
   "metadata": {},
   "source": [
    "(1) Start a new ChatBot session and discuss the relevance of learning and adaptability, communication, coding, and statistics and data analysis as skills in the modern world, especially with respect to career opportunities (particularly in the context of the data science industry)\n",
    "\n",
    "prompt:\n",
    "\n",
    "discuss the relevance of learning and adaptability, communication, coding, and statistics and data analysis as skills in the modern world, especially with respect to career opportunities (particularly in the context of the data science industry)\n",
    "\n",
    "\n",
    "ChatGPT respond:\n",
    "\n",
    "Learning and adaptability are crucial in today’s fast-paced world, especially in fields like data science. The landscape of technology and data is constantly evolving, so professionals must be willing to learn new tools, languages, and methodologies. This adaptability not only enhances individual skill sets but also allows teams and organizations to stay competitive.\n",
    "\n",
    "**Communication** is equally important. Data scientists often work with stakeholders from various backgrounds, translating complex data findings into actionable insights. Effective communication ensures that the implications of data analyses are understood and can inform decision-making processes. It helps bridge the gap between technical expertise and practical application, which is vital for collaborative projects.\n",
    "\n",
    "**Coding** skills are foundational for data science. Proficiency in programming languages like Python or R allows data scientists to manipulate data, automate processes, and implement algorithms. With the rise of machine learning and AI, coding enables professionals to build and deploy models that can drive business strategies.\n",
    "\n",
    "**Statistics and data analysis** provide the backbone for interpreting data. A strong grasp of statistical methods allows data scientists to derive meaningful conclusions from data sets, identify trends, and make predictions. This skill set is critical for validating hypotheses and ensuring that decisions are data-driven rather than based on intuition alone.\n",
    "\n",
    "Together, these skills create a strong profile for career opportunities in the data science industry. As organizations increasingly rely on data to drive their strategies, professionals who can adapt, communicate effectively, code, and analyze data will find themselves in high demand. The ability to combine these skills can lead to roles not just in data science, but also in business intelligence, analytics, and beyond, opening pathways to diverse career trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b2e42",
   "metadata": {},
   "source": [
    "(2) See if ChatBot thinks you could be a statistician or data scientist without coding or doing data analysis, and then transition your ChatBot conversation into a career exploration discussion, using the ChatBot to identify the skills that might be the most valuable for a career that you're interested\n",
    "\n",
    "prompt1:\n",
    "do you think you could be a statistician or data scientist without coding or doing data analysis? \n",
    "\n",
    "\n",
    "ChatGPT respond: \n",
    "It would be quite challenging to be a statistician or data scientist without coding or data analysis skills. Both roles heavily rely on the ability to manipulate data, perform statistical analyses, and implement algorithms—tasks that typically require coding.\n",
    "\n",
    "While a strong theoretical understanding of statistics is important, applying that knowledge to real-world data often necessitates coding for data cleaning, exploration, and model building. Additionally, data analysis involves interpreting results and communicating insights, which usually depends on having hands-on experience with data manipulation and analysis tools.\n",
    "\n",
    "In summary, while one could have a theoretical understanding of statistics and data science, practical skills in coding and data analysis are essential for effectively performing in these roles.\n",
    "\n",
    "\n",
    "prompt2: \n",
    "I want to become an Ai scientist or in general any position in AI industry, do I need those skills and the degree in those field? if not, are they required by the companies?\n",
    "\n",
    "ChatGPT respond: \n",
    "To become an AI scientist or work in the AI industry, having skills in coding, statistics, and data analysis is highly beneficial and often essential. Here’s a breakdown of what's typically expected:\n",
    "\n",
    "1. **Coding Skills**: Proficiency in programming languages like Python or R is crucial, as these are commonly used for building AI models, data manipulation, and implementing algorithms. Familiarity with libraries like TensorFlow, PyTorch, or scikit-learn can also be important.\n",
    "\n",
    "2. **Statistics and Mathematics**: A solid understanding of statistics, linear algebra, and calculus is necessary for developing and understanding AI algorithms. This knowledge helps in model evaluation, optimization, and understanding the underlying principles of machine learning.\n",
    "\n",
    "3. **Data Analysis**: Skills in data cleaning, exploration, and visualization are important, as working with data is a core part of AI projects. You need to be able to analyze data to derive insights and improve models.\n",
    "\n",
    "4. **Formal Education**: While a degree in a related field (such as computer science, mathematics, or engineering) can be beneficial and sometimes required, there are also many successful AI professionals who are self-taught or have taken specialized courses. Online platforms and bootcamps offer excellent resources for learning the necessary skills.\n",
    "\n",
    "5. **Industry Requirements**: Many companies look for candidates with a combination of relevant skills and experience rather than just formal degrees. Building a portfolio of projects, contributing to open-source initiatives, or engaging in internships can demonstrate your capabilities.\n",
    "\n",
    "In summary, while formal education can help, the skills you develop and how you apply them in practical situations are often more important in the AI field.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ddff87",
   "metadata": {},
   "source": [
    "(3) Ask for a summary of this ChatBot session and paste it into your homework notebook (including link(s) to chat log histories if you're using ChatBot)\n",
    "\n",
    "prompt:\n",
    "summarize our conversation so far\n",
    "\n",
    "\n",
    "ChatGPT:\n",
    "We've discussed the importance of learning and adaptability, communication, coding, and statistics/data analysis as essential skills for careers in the modern world, particularly in the data science and AI industries. You expressed interest in becoming an AI scientist or working in the AI field, and we highlighted that coding, statistical knowledge, and data analysis skills are typically required for such roles. We also noted that while formal education in related fields can be beneficial, many successful professionals are self-taught or have taken specialized courses, emphasizing the importance of practical skills and project experience.\n",
    "\n",
    "Link: https://chatgpt.com/share/66ecdef5-6598-800d-8cc6-a088a4d4215e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa124c",
   "metadata": {},
   "source": [
    "(4) Paraphrase the assessments and conclusions of your conversation in the form of a reflection on your current thoughts regarding your potential future career(s) and how you can go about building the skills you need to pursue it\n",
    "\n",
    "I have always wanted to work in AI industries since five years ago when I was in a fair about cybersecurity. They mentioned that a lot of discovery of bugs and the correspond defense system are based AI. At the time I thought to myself, AI is the future. Ever since then I started to work towards this goal. Until three years ago when ChatGPT is commonly known for everyone. Everyone was saying that we won't need to do or know as much about our job in the future we only need to know how to prompt and make the AI help us do the works. I was doubting that but after seeing the ability of ChatGPT in coding I thought that any industries or job that's based on code will all eventually replaced by AI and the demand will be significantly lower. Until today, I still kind of had the impression of I only need to know how to operate AI instead of learning every knowledge myself. But the respond from ChatGPT kind of wakes me up. Yes even if I don't know about the knowledge I still have the chance to get into the industries but process of entering and the afford I need to dedicate staying will be significaly larger. AI tools at least until this point or the next five to ten years will probably stay in the phase of being a tool that makes jobs easier instead of replacing the need of human to learn new, complicated knowledge. And now I also acknowledge, I have very little understanding in the industries I want to go into. I should continue using different ways to understand it more like AI tools, talk to people who's actually in the industries to understand more about my potential career development and be prepared for it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724650bc",
   "metadata": {},
   "source": [
    "(5) Give your thoughts regarding the helpfulness or limitations of your conversation with a ChatBot, and describe the next steps you would take to pursue this conversation further if you felt the information the ChatBot provides was somewhat high level and general, and perhaps lacked the depth and detailed knowledge of a dedicated subject matter expert who had really take the time to understand the ins and outs of the industry and career path in question.\n",
    "\n",
    "From my side, all through this interaction with ChatBot, I felt it to be more informative in giving a broad view of skills required for being a data scientist. It traced out in very brief form some of the important competencies which include coding, statistics, and explanations to them. Besides, since the information used to train ChatBot also emanates from online sources, these may be flawed. Although big data helps to eliminate the errors, it is not 100% guaranteed. Therefore, the errors in the information are very frequent. The other drawback from all this became limited, where information remained somewhat high-level, missed depth necessary, or even wrong for complete understanding in certain areas of the industry, either with regard to programming or actual practical applications. From here, I would go further by researching materials that concern the industry in question, connect with data scientists on LinkedIn, find mentors, take courses that cover a single skill-like machine learning or data visualization, and join communities with discussions on subjects related to your career goals. Such pragmatic knowledge with details rounds the basic understanding given by the ChatBot for an all-rounded approach in career building. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0ed9f",
   "metadata": {},
   "source": [
    "9. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228e459",
   "metadata": {},
   "source": [
    "YES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
